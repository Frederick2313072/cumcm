#!/usr/bin/env python3

import numpy as np
import librosa
import pandas as pd
from scipy import stats
from scipy.signal import hilbert
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import os
import glob
import warnings
import joblib
warnings.filterwarnings('ignore')

class MathematicalAudioFeatureExtractor:
    """åŸºäºä¸¥æ ¼æ•°å­¦ç†è®ºçš„éŸ³é¢‘ç‰¹å¾æå–å™¨
    
    è®¾è®¡åŸç†ï¼š
    1. ä¿¡å·å¤„ç†æ•°å­¦åŸºç¡€ï¼šå‚…é‡Œå¶å˜æ¢ã€å°æ³¢å˜æ¢ã€å¸Œå°”ä¼¯ç‰¹å˜æ¢
    2. ç»Ÿè®¡å­¦ç‰¹å¾ï¼šæ¦‚ç‡åˆ†å¸ƒã€ç†µç†è®ºã€é«˜é˜¶çŸ©
    3. ä¿¡æ¯è®ºï¼šäº’ä¿¡æ¯ã€å¤æ‚åº¦åº¦é‡
    4. å¯è§£é‡Šæ€§ï¼šæ¯ä¸ªç‰¹å¾éƒ½æœ‰æ˜ç¡®çš„ç‰©ç†/æ•°å­¦å«ä¹‰
    """
    
    def __init__(self, sr=22050):
        self.sr = sr
        print(f"[æ•°å­¦ç‰¹å¾æå–å™¨] åˆå§‹åŒ–å®Œæˆï¼Œé‡‡æ ·ç‡={sr}Hz")
        
    def extract_spectral_mathematical_features(self, y):
        """é¢‘åŸŸæ•°å­¦ç‰¹å¾ï¼šåŸºäºå‚…é‡Œå¶åˆ†æå’Œç»Ÿè®¡å­¦ç†è®º"""
        features = {}
        print(f"[é¢‘åŸŸæ•°å­¦] å¼€å§‹é¢‘åŸŸç‰¹å¾æå–...")
        
        # è®¡ç®—STFT - çŸ­æ—¶å‚…é‡Œå¶å˜æ¢
        stft = librosa.stft(y, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        power_spectrum = magnitude ** 2
        
        # 1. é¢‘è°±è´¨å¿ƒ - é¢‘ç‡çš„åŠ æƒå¹³å‡ï¼ˆç‰©ç†å«ä¹‰ï¼šéŸ³è‰²äº®åº¦ï¼‰
        freq_bins = np.fft.fftfreq(stft.shape[0], 1/self.sr)[:stft.shape[0]//2]
        spectral_centroids = librosa.feature.spectral_centroid(S=magnitude, sr=self.sr)[0]
        
        # æ•°å­¦ç‰¹å¾ï¼šè´¨å¿ƒçš„ç»Ÿè®¡ç‰¹æ€§
        features['spectral_centroid_mean'] = np.mean(spectral_centroids)
        features['spectral_centroid_std'] = np.std(spectral_centroids)
        
        # è´¨å¿ƒå˜åŒ–ç‡ï¼ˆä¸€é˜¶å·®åˆ†çš„æ ‡å‡†å·®ï¼‰- åæ˜ éŸ³è‰²å˜åŒ–çš„ç¨³å®šæ€§
        centroid_diff = np.diff(spectral_centroids)
        features['centroid_stability'] = 1.0 / (1.0 + np.std(centroid_diff))
        
        # é¢‘è°±è´¨å¿ƒè½¨è¿¹å¹³æ»‘åº¦ - AIéŸ³ä¹è´¨å¿ƒè½¨è¿¹æ›´å¹³æ»‘
        if len(spectral_centroids) > 2:
            centroid_correlation = np.corrcoef(spectral_centroids[:-1], spectral_centroids[1:])[0, 1]
            features['centroid_trajectory_smoothness'] = centroid_correlation if not np.isnan(centroid_correlation) else 0.5
        else:
            features['centroid_trajectory_smoothness'] = 0.5
        
        print(f"[é¢‘åŸŸæ•°å­¦] é¢‘è°±è´¨å¿ƒå¢å¼ºç‰¹å¾å®Œæˆ")
        
        # 2. é¢‘è°±å¸¦å®½ - é¢‘ç‡åˆ†å¸ƒçš„æ ‡å‡†å·®ï¼ˆåæ˜ é¢‘è°±çš„é›†ä¸­ç¨‹åº¦ï¼‰
        spectral_bandwidth = librosa.feature.spectral_bandwidth(S=magnitude, sr=self.sr)[0]
        features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)
        features['spectral_bandwidth_std'] = np.std(spectral_bandwidth)
        print(f"[é¢‘åŸŸæ•°å­¦] é¢‘è°±å¸¦å®½ç‰¹å¾å®Œæˆ")
        
        # 3. é¢‘è°±ç†µ - ä¿¡æ¯è®ºåº¦é‡ï¼ˆåæ˜ é¢‘è°±å¤æ‚åº¦ï¼‰
        # H(X) = -âˆ‘ p(x) log p(x)
        power_normalized = power_spectrum / (np.sum(power_spectrum, axis=0, keepdims=True) + 1e-10)
        spectral_entropy = -np.sum(power_normalized * np.log(power_normalized + 1e-10), axis=0)
        features['spectral_entropy_mean'] = np.mean(spectral_entropy)
        features['spectral_entropy_std'] = np.std(spectral_entropy)
        print(f"[é¢‘åŸŸæ•°å­¦] é¢‘è°±ç†µç‰¹å¾å®Œæˆ")
        
        # 4. é¢‘è°±å¹³å¦åº¦ - Wienerç†µï¼ˆåæ˜ å™ªå£°ç‰¹æ€§ï¼‰
        # å‡ ä½•å¹³å‡ / ç®—æœ¯å¹³å‡
        geometric_mean = np.exp(np.mean(np.log(magnitude + 1e-10), axis=0))
        arithmetic_mean = np.mean(magnitude, axis=0)
        spectral_flatness = geometric_mean / (arithmetic_mean + 1e-10)
        features['spectral_flatness_mean'] = np.mean(spectral_flatness)
        features['spectral_flatness_std'] = np.std(spectral_flatness)
        print(f"[é¢‘åŸŸæ•°å­¦] é¢‘è°±å¹³å¦åº¦ç‰¹å¾å®Œæˆ")
        
        # 5. è°æ³¢-å™ªå£°æ¯”å¢å¼ºç‰¹å¾ - åŸºäºé‡è¦æ€§åˆ†æçš„å…³é”®ç‰¹å¾
        try:
            harmonic, percussive = librosa.effects.hpss(y)
            harmonic_rms = librosa.feature.rms(y=harmonic)[0]
            percussive_rms = librosa.feature.rms(y=percussive)[0]
            
            harmonic_energy = np.mean(harmonic_rms)
            percussive_energy = np.mean(percussive_rms)
            features['harmonic_noise_ratio'] = np.log10(harmonic_energy / (percussive_energy + 1e-10))
            
            # è°æ³¢å¤æ‚åº¦ - AIéŸ³ä¹è°æ³¢ç»“æ„æ›´ç®€å•
            features['harmonic_complexity'] = np.std(harmonic_rms) / (np.mean(harmonic_rms) + 1e-10)
            
            # è°æ³¢-å™ªå£°å¹³è¡¡ç¨³å®šæ€§ - AIéŸ³ä¹å¹³è¡¡æ›´ç¨³å®š
            hnr_frames = harmonic_rms / (percussive_rms + 1e-10)
            features['hnr_stability'] = 1.0 / (1.0 + np.std(np.log10(hnr_frames + 1e-10)))
            
            print(f"[é¢‘åŸŸæ•°å­¦] è°æ³¢-å™ªå£°æ¯”å¢å¼ºç‰¹å¾å®Œæˆ")
        except:
            features['harmonic_noise_ratio'] = 0.0
            features['harmonic_complexity'] = 0.5
            features['hnr_stability'] = 0.5
            print(f"[é¢‘åŸŸæ•°å­¦] è°æ³¢-å™ªå£°æ¯”è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        return features
    
    def extract_temporal_mathematical_features(self, y):
        """æ—¶åŸŸæ•°å­¦ç‰¹å¾ï¼šåŸºäºç»Ÿè®¡å­¦å’Œä¿¡å·å¤„ç†ç†è®º"""
        features = {}
        print(f"[æ—¶åŸŸæ•°å­¦] å¼€å§‹æ—¶åŸŸç‰¹å¾æå–...")
        
        # é™åˆ¶éŸ³é¢‘é•¿åº¦é¿å…è®¡ç®—å¤æ‚åº¦è¿‡é«˜
        max_len = min(len(y), 220500)  # çº¦10ç§’
        y_analysis = y[:max_len]
        
        # 1. å¹…åº¦ç»Ÿè®¡ç‰¹å¾ - åŸºäºæ¦‚ç‡åˆ†å¸ƒç†è®º
        print(f"[æ—¶åŸŸæ•°å­¦] è®¡ç®—å¹…åº¦ç»Ÿè®¡ç‰¹å¾...")
        features['amplitude_mean'] = np.mean(np.abs(y_analysis))
        features['amplitude_std'] = np.std(y_analysis)
        features['amplitude_skewness'] = stats.skew(y_analysis)  # ååº¦
        features['amplitude_kurtosis'] = stats.kurtosis(y_analysis)  # å³°åº¦
        
        # 2. é›¶äº¤å‰ç‡å¢å¼ºç‰¹å¾ - åŸºäºé‡è¦æ€§åˆ†æçš„å…³é”®ç‰¹å¾
        print(f"[æ—¶åŸŸæ•°å­¦] è®¡ç®—é›¶äº¤å‰ç‡å¢å¼ºç‰¹å¾...")
        zcr = librosa.feature.zero_crossing_rate(y_analysis, frame_length=2048, hop_length=512)[0]
        features['zcr_mean'] = np.mean(zcr)
        features['zcr_std'] = np.std(zcr)
        features['zcr_entropy'] = -np.sum(zcr * np.log(zcr + 1e-10)) / len(zcr)
        
        # ZCRæ—¶åºç¨³å®šæ€§ - AIéŸ³ä¹ZCRå˜åŒ–æ›´è§„å¾‹
        zcr_diff = np.diff(zcr)
        features['zcr_stability'] = 1.0 / (1.0 + np.std(zcr_diff))
        
        # ZCRå¼‚å¸¸å€¼æ£€æµ‹ - AIéŸ³ä¹å¼‚å¸¸ZCRæ›´é¢‘ç¹
        zcr_median = np.median(zcr)
        zcr_mad = np.median(np.abs(zcr - zcr_median))  # ä¸­ä½æ•°ç»å¯¹åå·®
        features['zcr_outlier_ratio'] = np.sum(np.abs(zcr - zcr_median) > 2 * zcr_mad) / len(zcr)
        
        # 3. RMSèƒ½é‡ç‰¹å¾ - åŠ¨æ€èŒƒå›´åˆ†æ
        print(f"[æ—¶åŸŸæ•°å­¦] è®¡ç®—RMSèƒ½é‡ç‰¹å¾...")
        rms = librosa.feature.rms(y=y_analysis, frame_length=2048, hop_length=512)[0]
        features['rms_mean'] = np.mean(rms)
        features['rms_std'] = np.std(rms)
        
        # åŠ¨æ€èŒƒå›´å‹ç¼©æŒ‡æ ‡ï¼ˆAIéŸ³ä¹é€šå¸¸å‹ç¼©æ›´å¼ºï¼‰
        rms_db = 20 * np.log10(rms + 1e-10)
        features['dynamic_range'] = np.max(rms_db) - np.min(rms_db)
        features['compression_ratio'] = np.std(rms_db) / (np.mean(rms_db) + 1e-10)
        
        # 4. çŸ­æ—¶èƒ½é‡å˜åŒ–ç‡ - èŠ‚å¥ç¨³å®šæ€§
        print(f"[æ—¶åŸŸæ•°å­¦] è®¡ç®—èƒ½é‡å˜åŒ–ç‡...")
        energy_diff = np.diff(rms)
        features['energy_variation'] = np.std(energy_diff)
        features['energy_regularity'] = 1.0 / (1.0 + np.std(energy_diff))
        
        # 5. è‡ªç›¸å…³ç‰¹å¾ - å‘¨æœŸæ€§åˆ†æï¼ˆç®€åŒ–ç‰ˆé¿å…å¤æ‚åº¦è¿‡é«˜ï¼‰
        print(f"[æ—¶åŸŸæ•°å­¦] è®¡ç®—è‡ªç›¸å…³ç‰¹å¾...")
        try:
            # ä½¿ç”¨è¾ƒçŸ­çš„çª—å£è®¡ç®—è‡ªç›¸å…³
            window_size = min(8192, len(y_analysis))
            y_window = y_analysis[:window_size]
            
            # è®¡ç®—å½’ä¸€åŒ–è‡ªç›¸å…³
            autocorr = np.correlate(y_window, y_window, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            autocorr_norm = autocorr / (autocorr[0] + 1e-10)
            
            # å¯»æ‰¾ç¬¬ä¸€ä¸ªæ˜¾è‘—å³°å€¼ï¼ˆåŸºé¢‘ä¼°è®¡ï¼‰
            first_peak_idx = 1
            for i in range(1, min(len(autocorr_norm)//4, 1000)):
                if (autocorr_norm[i] > autocorr_norm[i-1] and 
                    autocorr_norm[i] > autocorr_norm[i+1] and 
                    autocorr_norm[i] > 0.3):
                    first_peak_idx = i
                    break
            
            features['periodicity_strength'] = autocorr_norm[first_peak_idx] if first_peak_idx > 1 else 0.1
            features['fundamental_period'] = first_peak_idx / self.sr if first_peak_idx > 1 else 0.01
            
            print(f"[æ—¶åŸŸæ•°å­¦] è‡ªç›¸å…³ç‰¹å¾å®Œæˆï¼Œå‘¨æœŸå¼ºåº¦={features['periodicity_strength']:.3f}")
            
        except Exception as e:
            print(f"[æ—¶åŸŸæ•°å­¦] è‡ªç›¸å…³è®¡ç®—å¤±è´¥: {e}")
            features['periodicity_strength'] = 0.1
            features['fundamental_period'] = 0.01
        
        return features
    
    def extract_musical_mathematical_features(self, y):
        """éŸ³ä¹ç†è®ºæ•°å­¦ç‰¹å¾ï¼šåŸºäºéŸ³ä¹å£°å­¦å’Œä¿¡å·å¤„ç†"""
        features = {}
        print(f"[éŸ³ä¹æ•°å­¦] å¼€å§‹éŸ³ä¹ç†è®ºç‰¹å¾æå–...")
        
        # ä½¿ç”¨é€‚ä¸­é•¿åº¦çš„éŸ³é¢‘æ®µ
        max_len = min(len(y), 110250)  # çº¦5ç§’
        y_music = y[:max_len]
        
        # 1. MFCCç‰¹å¾ - åŸºäºäººè€³æ„ŸçŸ¥æ¨¡å‹çš„å€’è°±åˆ†æ
        print(f"[éŸ³ä¹æ•°å­¦] è®¡ç®—MFCCç‰¹å¾...")
        try:
            mfcc = librosa.feature.mfcc(y=y_music, sr=self.sr, n_mfcc=13, n_fft=2048)
            
            # MFCCç»Ÿè®¡ç‰¹å¾
            features['mfcc_mean_1'] = np.mean(mfcc[1])  # ç¬¬1ä¸ªMFCCç³»æ•°
            features['mfcc_mean_2'] = np.mean(mfcc[2])  # ç¬¬2ä¸ªMFCCç³»æ•°
            features['mfcc_std_1'] = np.std(mfcc[1])
            features['mfcc_std_2'] = np.std(mfcc[2])
            
            # MFCCç³»æ•°é—´çš„ç›¸å…³æ€§ï¼ˆåæ˜ éŸ³è‰²ä¸€è‡´æ€§ï¼‰
            if mfcc.shape[0] >= 3 and mfcc.shape[1] >= 10:
                corr_12 = np.corrcoef(mfcc[1], mfcc[2])[0, 1]
                corr_23 = np.corrcoef(mfcc[2], mfcc[3])[0, 1]
                features['mfcc_correlation'] = np.mean([abs(corr_12), abs(corr_23)])
            else:
                features['mfcc_correlation'] = 0.5
            
            print(f"[éŸ³ä¹æ•°å­¦] MFCCç‰¹å¾å®Œæˆ")
            
        except Exception as e:
            print(f"[éŸ³ä¹æ•°å­¦] MFCCè®¡ç®—å¤±è´¥: {e}")
            features['mfcc_mean_1'] = 0.0
            features['mfcc_mean_2'] = 0.0
            features['mfcc_std_1'] = 1.0
            features['mfcc_std_2'] = 1.0
            features['mfcc_correlation'] = 0.5
        
        # 2. ç®€åŒ–çš„é¢‘è°±èƒ½é‡ç‰¹å¾ï¼ˆæ›¿ä»£è‰²åº¦ç‰¹å¾ï¼Œé¿å…æ®µé”™è¯¯ï¼‰
        print(f"[éŸ³ä¹æ•°å­¦] è®¡ç®—é¢‘è°±èƒ½é‡ç‰¹å¾...")
        try:
            # ä½¿ç”¨æ›´å®‰å…¨çš„é¢‘è°±åˆ†ææ–¹æ³•
            # é™åˆ¶éŸ³é¢‘é•¿åº¦å’ŒFFTå‚æ•°
            y_safe = y_music[:min(len(y_music), self.sr * 15)]  # é™åˆ¶åˆ°15ç§’
            
            if len(y_safe) < 1024:
                # éŸ³é¢‘å¤ªçŸ­ï¼Œä½¿ç”¨é»˜è®¤å€¼
                features['chroma_std'] = 0.1
                features['pitch_stability'] = 0.3
                features['pitch_entropy'] = 2.0
            else:
                # ä½¿ç”¨numpy FFTè¿›è¡Œé¢‘è°±åˆ†æï¼Œé¿å…librosaçš„å¤æ‚è®¡ç®—
                # åˆ†æ®µå¤„ç†ï¼Œæ¯æ®µ1ç§’
                segment_length = self.sr
                segments = []
                
                for i in range(0, len(y_safe), segment_length):
                    segment = y_safe[i:i + segment_length]
                    if len(segment) >= 1024:
                        # è®¡ç®—è¯¥æ®µçš„FFT
                        fft_result = np.fft.fft(segment, n=2048)
                        magnitude = np.abs(fft_result[:1024])  # åªå–æ­£é¢‘ç‡éƒ¨åˆ†
                        
                        # å°†é¢‘è°±åˆ†ä¸º12ä¸ªåŒºé—´ï¼ˆæ¨¡æ‹Ÿè‰²åº¦ï¼‰
                        freq_bins = len(magnitude)
                        bin_size = freq_bins // 12
                        chroma_like = []
                        
                        for j in range(12):
                            start_idx = j * bin_size
                            end_idx = min((j + 1) * bin_size, freq_bins)
                            if start_idx < end_idx:
                                bin_energy = np.mean(magnitude[start_idx:end_idx])
                                chroma_like.append(bin_energy)
                        
                        if len(chroma_like) == 12:
                            segments.append(chroma_like)
                
                if segments:
                    # è®¡ç®—æ‰€æœ‰æ®µçš„å¹³å‡è‰²åº¦ç‰¹å¾
                    segments_array = np.array(segments)
                    chroma_mean = np.mean(segments_array, axis=0)
                    
                    # å½’ä¸€åŒ–
                    chroma_sum = np.sum(chroma_mean) + 1e-10
                    chroma_norm = chroma_mean / chroma_sum
                    
                    # è®¡ç®—ç‰¹å¾
                    features['chroma_std'] = np.std(chroma_norm)
                    features['pitch_stability'] = np.max(chroma_norm)
                    features['pitch_entropy'] = -np.sum(chroma_norm * np.log(chroma_norm + 1e-10))
                else:
                    features['chroma_std'] = 0.1
                    features['pitch_stability'] = 0.3
                    features['pitch_entropy'] = 2.0
            
            print(f"[éŸ³ä¹æ•°å­¦] é¢‘è°±èƒ½é‡ç‰¹å¾å®Œæˆ")
            
        except Exception as e:
            print(f"[éŸ³ä¹æ•°å­¦] é¢‘è°±èƒ½é‡ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            features['chroma_std'] = 0.1
            features['pitch_stability'] = 0.3
            features['pitch_entropy'] = 2.0
        
        # 3. èŠ‚å¥ç‰¹å¾ - åŸºäºèƒ½é‡å˜åŒ–çš„èŠ‚æ‹åˆ†æ
        print(f"[éŸ³ä¹æ•°å­¦] è®¡ç®—èŠ‚å¥ç‰¹å¾...")
        try:
            # è®¡ç®—èŠ‚æ‹å¼ºåº¦å‡½æ•°
            hop_length = 512
            frame_length = 2048
            
            # ä½¿ç”¨é¢‘è°±æµé‡ï¼ˆSpectral Fluxï¼‰æ£€æµ‹èŠ‚æ‹
            stft = librosa.stft(y_music, n_fft=frame_length, hop_length=hop_length)
            magnitude = np.abs(stft)
            
            # è®¡ç®—ç›¸é‚»å¸§é—´çš„é¢‘è°±å·®å¼‚
            spectral_diff = np.diff(magnitude, axis=1)
            spectral_flux = np.sum(np.maximum(0, spectral_diff), axis=0)
            
            # èŠ‚æ‹å¼ºåº¦çš„ç»Ÿè®¡ç‰¹å¾
            features['rhythm_intensity_mean'] = np.mean(spectral_flux)
            features['rhythm_intensity_std'] = np.std(spectral_flux)
            features['rhythm_regularity'] = 1.0 / (1.0 + np.std(np.diff(spectral_flux)))
            
            print(f"[éŸ³ä¹æ•°å­¦] èŠ‚å¥ç‰¹å¾å®Œæˆ")
            
        except Exception as e:
            print(f"[éŸ³ä¹æ•°å­¦] èŠ‚å¥è®¡ç®—å¤±è´¥: {e}")
            features['rhythm_intensity_mean'] = 0.1
            features['rhythm_intensity_std'] = 0.05
            features['rhythm_regularity'] = 0.5
        
        # 4. éŸ³è‰²ç‰¹å¾ - åŸºäºé¢‘è°±é‡å¿ƒå’Œå¸¦å®½
        print(f"[éŸ³ä¹æ•°å­¦] è®¡ç®—éŸ³è‰²ç‰¹å¾...")
        try:
            # ä½¿ç”¨å·²è®¡ç®—çš„STFT
            if 'stft' in locals():
                magnitude = np.abs(stft)
            else:
                stft = librosa.stft(y_music, n_fft=2048, hop_length=512)
                magnitude = np.abs(stft)
            
            # é¢‘è°±é‡å¿ƒï¼ˆäº®åº¦ï¼‰
            spectral_centroids = librosa.feature.spectral_centroid(S=magnitude, sr=self.sr)[0]
            features['timbre_brightness'] = np.mean(spectral_centroids)
            features['timbre_brightness_var'] = np.var(spectral_centroids)
            
            # é¢‘è°±æ»šé™ç‚¹ï¼ˆé«˜é¢‘å†…å®¹ï¼‰
            spectral_rolloff = librosa.feature.spectral_rolloff(S=magnitude, sr=self.sr)[0]
            features['timbre_rolloff'] = np.mean(spectral_rolloff)
            
            print(f"[éŸ³ä¹æ•°å­¦] éŸ³è‰²ç‰¹å¾å®Œæˆ")
            
        except Exception as e:
            print(f"[éŸ³ä¹æ•°å­¦] éŸ³è‰²è®¡ç®—å¤±è´¥: {e}")
            features['timbre_brightness'] = 1000.0
            features['timbre_brightness_var'] = 100000.0
            features['timbre_rolloff'] = 2000.0
        
        return features
    
    def extract_all_features(self, audio_file):
        """æå–æ‰€æœ‰æ•°å­¦ç‰¹å¾"""
        import time
        import os
        
        start_time = time.time()
        filename = os.path.basename(audio_file)
        print(f"[DEBUG] å¼€å§‹å¤„ç†: {filename}")
        
        try:
            # æ·»åŠ éŸ³é¢‘åŠ è½½è¶…æ—¶æ£€æŸ¥
            print(f"[DEBUG] {filename}: åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
            load_start = time.time()
            y, sr = librosa.load(audio_file, sr=self.sr)
            load_time = time.time() - load_start
            print(f"[DEBUG] {filename}: éŸ³é¢‘åŠ è½½å®Œæˆï¼Œè€—æ—¶ {load_time:.2f}sï¼Œé•¿åº¦ {len(y)} é‡‡æ ·ç‚¹")
            
            # éŸ³é¢‘é¢„å¤„ç†
            print(f"[DEBUG] {filename}: éŸ³é¢‘é¢„å¤„ç†...")
            y = librosa.util.normalize(y)
            
            features = {}
            
            # æå–å„ç±»æ•°å­¦ç‰¹å¾
            print(f"[DEBUG] {filename}: æå–é¢‘åŸŸç‰¹å¾...")
            spectral_features = self.extract_spectral_mathematical_features(y)
            print(f"[DEBUG] {filename}: é¢‘åŸŸç‰¹å¾å®Œæˆ")
            
            print(f"[DEBUG] {filename}: æå–æ—¶åŸŸç‰¹å¾...")
            temporal_features = self.extract_temporal_mathematical_features(y)
            print(f"[DEBUG] {filename}: æ—¶åŸŸç‰¹å¾å®Œæˆ")
            
            print(f"[DEBUG] {filename}: æå–éŸ³ä¹å­¦ç‰¹å¾...")
            musical_features = self.extract_musical_mathematical_features(y)
            print(f"[DEBUG] {filename}: éŸ³ä¹å­¦ç‰¹å¾å®Œæˆ")
            
            features.update(spectral_features)
            features.update(temporal_features)  
            features.update(musical_features)
            
            total_time = time.time() - start_time
            print(f"[DEBUG] {filename}: ç‰¹å¾æå–å®Œæˆï¼Œæ€»è€—æ—¶ {total_time:.2f}s")
            return features
            
        except Exception as e:
            error_time = time.time() - start_time
            print(f"[ERROR] {filename}: ç‰¹å¾æå–é”™è¯¯ ({error_time:.2f}s): {e}")
            # è¿”å›é»˜è®¤ç‰¹å¾å€¼
            return {f'feature_{i}': 0.0 for i in range(15)}


class MathematicalAIMusicDetector:
    """åŸºäºæ•°å­¦ç‰¹å¾çš„AIéŸ³ä¹æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.feature_extractor = MathematicalAudioFeatureExtractor()
        self.scaler = StandardScaler()
        self.model = None
        self.feature_names = None
        
        # æ¨¡å‹ç¼“å­˜é…ç½®
        self.model_cache_path = "ai_music_detector_model.pkl"
        self.scaler_cache_path = "ai_music_detector_scaler.pkl"
        self.threshold_cache_path = "ai_music_detector_threshold.pkl"
        
    def save_model_cache(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°ç¼“å­˜æ–‡ä»¶"""
        try:
            # ä¿å­˜æ¨¡å‹
            if self.model is not None:
                joblib.dump(self.model, self.model_cache_path)
                print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {self.model_cache_path}")
            
            # ä¿å­˜æ ‡å‡†åŒ–å™¨
            if self.scaler is not None:
                joblib.dump(self.scaler, self.scaler_cache_path)
                print(f"âœ… æ ‡å‡†åŒ–å™¨å·²ä¿å­˜åˆ°: {self.scaler_cache_path}")
            
            # ä¿å­˜æœ€ä¼˜é˜ˆå€¼
            if hasattr(self, 'optimal_threshold'):
                joblib.dump(self.optimal_threshold, self.threshold_cache_path)
                print(f"âœ… æœ€ä¼˜é˜ˆå€¼å·²ä¿å­˜åˆ°: {self.threshold_cache_path}")
                
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¨¡å‹ç¼“å­˜å¤±è´¥: {e}")
    
    def load_model_cache(self):
        """ä»ç¼“å­˜æ–‡ä»¶åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
        try:
            # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not (os.path.exists(self.model_cache_path) and 
                   os.path.exists(self.scaler_cache_path)):
                print("ğŸ“ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
                return False
            
            # åŠ è½½æ¨¡å‹
            print("ğŸ”„ æ­£åœ¨åŠ è½½ç¼“å­˜çš„æ¨¡å‹...")
            self.model = joblib.load(self.model_cache_path)
            print(f"âœ… æ¨¡å‹å·²ä»ç¼“å­˜åŠ è½½: {self.model_cache_path}")
            
            # åŠ è½½æ ‡å‡†åŒ–å™¨
            self.scaler = joblib.load(self.scaler_cache_path)
            print(f"âœ… æ ‡å‡†åŒ–å™¨å·²ä»ç¼“å­˜åŠ è½½: {self.scaler_cache_path}")
            
            # åŠ è½½æœ€ä¼˜é˜ˆå€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if os.path.exists(self.threshold_cache_path):
                self.optimal_threshold = joblib.load(self.threshold_cache_path)
                print(f"âœ… æœ€ä¼˜é˜ˆå€¼å·²ä»ç¼“å­˜åŠ è½½: {self.threshold_cache_path}")
            else:
                self.optimal_threshold = 0.5
                print("âš ï¸  æœªæ‰¾åˆ°é˜ˆå€¼ç¼“å­˜ï¼Œä½¿ç”¨é»˜è®¤é˜ˆå€¼ 0.5")
            
            print("ğŸš€ æ¨¡å‹ç¼“å­˜åŠ è½½æˆåŠŸï¼èŠ‚çœäº†å¤§é‡è®­ç»ƒæ—¶é—´")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹ç¼“å­˜å¤±è´¥: {e}")
            print("ğŸ”„ å°†é‡æ–°è®­ç»ƒæ¨¡å‹...")
            return False
    
    def clear_model_cache(self):
        """æ¸…é™¤æ¨¡å‹ç¼“å­˜æ–‡ä»¶"""
        cache_files = [self.model_cache_path, self.scaler_cache_path, self.threshold_cache_path]
        cleared_count = 0
        
        for cache_file in cache_files:
            if os.path.exists(cache_file):
                try:
                    os.remove(cache_file)
                    print(f"ğŸ—‘ï¸  å·²åˆ é™¤ç¼“å­˜æ–‡ä»¶: {cache_file}")
                    cleared_count += 1
                except Exception as e:
                    print(f"âŒ åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {e}")
        
        if cleared_count > 0:
            print(f"âœ… å·²æ¸…é™¤ {cleared_count} ä¸ªç¼“å­˜æ–‡ä»¶")
        else:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…é™¤çš„ç¼“å­˜æ–‡ä»¶")
        
    def _create_interpretable_ensemble(self):
        """åˆ›å»ºé˜²è¿‡æ‹Ÿåˆçš„å¯è§£é‡Šé›†æˆæ¨¡å‹"""
        # éšæœºæ£®æ—ï¼šå‡å°‘è¿‡æ‹Ÿåˆçš„å‚æ•°è®¾ç½®
        rf = RandomForestClassifier(
            n_estimators=150,  # å¢åŠ æ ‘æ•°é‡æé«˜ç¨³å®šæ€§
            max_depth=8,       # é™ä½æ ‘æ·±åº¦é˜²æ­¢è¿‡æ‹Ÿåˆ
            min_samples_split=10,  # å¢åŠ åˆ†è£‚æœ€å°æ ·æœ¬æ•°
            min_samples_leaf=5,    # å¢åŠ å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
            max_features='sqrt',   # é™åˆ¶ç‰¹å¾æ•°é‡
            random_state=42,
            class_weight='balanced',
            bootstrap=True,        # å¯ç”¨bootstrapé‡‡æ ·
            oob_score=True        # è®¡ç®—è¢‹å¤–å¾—åˆ†
        )
        
        # é€»è¾‘å›å½’ï¼šå¢å¼ºæ­£åˆ™åŒ–
        lr = LogisticRegression(
            random_state=42,
            class_weight='balanced',
            max_iter=3000,
            C=0.01,           # æ›´å¼ºçš„L2æ­£åˆ™åŒ–
            penalty='l2',     # æ˜ç¡®æŒ‡å®šL2æ­£åˆ™åŒ–
            solver='liblinear'  # é€‚åˆå°æ•°æ®é›†
        )
        
        # æ”¯æŒå‘é‡æœºï¼šé˜²è¿‡æ‹Ÿåˆå‚æ•°
        svm = SVC(
            probability=True, 
            random_state=42,
            class_weight='balanced',
            kernel='rbf',
            C=0.5,           # é™ä½Cå€¼å¢åŠ æ­£åˆ™åŒ–
            gamma='scale'
        )
        
        try:
            # å°è¯•ä½¿ç”¨XGBoostå¢å¼ºæ€§èƒ½
            from xgboost import XGBClassifier
            xgb = XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42,
                eval_metric='logloss'
            )
            
            # å››æ¨¡å‹é›†æˆ
            ensemble = VotingClassifier(
                estimators=[('rf', rf), ('lr', lr), ('svm', svm), ('xgb', xgb)],
                voting='soft'
            )
            print("ä½¿ç”¨å¢å¼ºå››æ¨¡å‹é›†æˆï¼ˆRF+LR+SVM+XGBï¼‰")
            
        except ImportError:
            # å›é€€åˆ°ä¸‰æ¨¡å‹é›†æˆ
            ensemble = VotingClassifier(
                estimators=[('rf', rf), ('lr', lr), ('svm', svm)],
                voting='soft'
            )
            print("ä½¿ç”¨ä¸‰æ¨¡å‹é›†æˆï¼ˆRF+LR+SVMï¼‰")
        
        return ensemble
    
    def train_with_real_data(self, training_data_path="é™„ä»¶å…­ï¼šè®­ç»ƒæ•°æ®"):
        """ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®è®­ç»ƒæ¨¡å‹"""
        print("åŸºäºçœŸå®éŸ³é¢‘æ•°æ®è®­ç»ƒæ¨¡å‹...")
        
        # é¦–å…ˆå°è¯•ä»ç¼“å­˜åŠ è½½æ¨¡å‹
        if self.load_model_cache():
            print("âœ… ä»ç¼“å­˜åŠ è½½æ¨¡å‹æˆåŠŸï¼Œè·³è¿‡è®­ç»ƒè¿‡ç¨‹")
            return self
        
        print("ğŸ“š å¼€å§‹é‡æ–°è®­ç»ƒæ¨¡å‹...")
        from sklearn.model_selection import train_test_split
        
        # AIç”ŸæˆéŸ³ä¹æ–‡ä»¶å¤¹ï¼ˆæ ‡ç­¾=1ï¼‰
        ai_folders = ['alice', 'china_vocaloid', 'game', 'gugugaga', 'ikun', 'manbo', 'yiwu']
        # éAIç”ŸæˆéŸ³ä¹æ–‡ä»¶å¤¹ï¼ˆæ ‡ç­¾=0ï¼‰
        human_folders = ['hanser', 'tianyi_daddy', 'xiangsi', 'xiexiemiao~']
        
        # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶è·¯å¾„å’Œæ ‡ç­¾
        audio_files = []
        labels = []
        
        # AIç”ŸæˆéŸ³ä¹
        for folder in ai_folders:
            folder_path = os.path.join(training_data_path, folder)
            if os.path.exists(folder_path):
                # æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼
                for ext in ['*.mp3', '*.aac', '*.wav', '*.flac']:
                    files = glob.glob(os.path.join(folder_path, ext))
                    audio_files.extend(files)
                    labels.extend([1] * len(files))  # AI=1
                print(f"AIç±»åˆ« {folder}: æ‰¾åˆ° {len(glob.glob(os.path.join(folder_path, '*.*')))} ä¸ªæ–‡ä»¶")
        
        # äººç±»åˆ›ä½œéŸ³ä¹  
        for folder in human_folders:
            folder_path = os.path.join(training_data_path, folder)
            if os.path.exists(folder_path):
                for ext in ['*.mp3', '*.aac', '*.wav', '*.flac']:
                    files = glob.glob(os.path.join(folder_path, ext))
                    audio_files.extend(files)
                    labels.extend([0] * len(files))  # äººç±»=0
                print(f"äººç±»ç±»åˆ« {folder}: æ‰¾åˆ° {len(glob.glob(os.path.join(folder_path, '*.*')))} ä¸ªæ–‡ä»¶")
        
        print(f"æ€»è®¡: {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        print(f"AIç”Ÿæˆ: {sum(labels)} ä¸ª, äººç±»åˆ›ä½œ: {len(labels) - sum(labels)} ä¸ª")
        
        if len(audio_files) == 0:
            raise FileNotFoundError("é”™è¯¯: æœªæ‰¾åˆ°è®­ç»ƒéŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥é™„ä»¶å…­ï¼šè®­ç»ƒæ•°æ®ç›®å½•")
        
        # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥é¿å…è¿‡é•¿è®­ç»ƒæ—¶é—´
        max_samples_per_class = 50
        ai_files = [(f, l) for f, l in zip(audio_files, labels) if l == 1][:max_samples_per_class]
        human_files = [(f, l) for f, l in zip(audio_files, labels) if l == 0][:max_samples_per_class]
        
        selected_files = ai_files + human_files
        audio_files = [f for f, l in selected_files]
        labels = [l for f, l in selected_files]
        
        print(f"é€‰æ‹©è®­ç»ƒæ ·æœ¬: AI={len(ai_files)}, äººç±»={len(human_files)}")
        
        # æ‰“å°å³å°†å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
        print("\n[INFO] å³å°†å¤„ç†çš„éŸ³é¢‘æ–‡ä»¶:")
        for i, (af, lbl) in enumerate(zip(audio_files[:10], labels[:10])):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  {i+1}. {os.path.basename(af)} ({'AI' if lbl==1 else 'äººç±»'})")
        if len(audio_files) > 10:
            print(f"  ... è¿˜æœ‰ {len(audio_files)-10} ä¸ªæ–‡ä»¶")
        
        # æå–ç‰¹å¾ï¼ˆæ”¯æŒå¹¶è¡Œå¤„ç†ï¼‰
        print("\n[INFO] å¼€å§‹æå–éŸ³é¢‘ç‰¹å¾...")
        try:
            from joblib import Parallel, delayed
            from tqdm import tqdm
            
            def extract_single_feature(audio_file, label):
                import time
                import signal
                import os
                
                filename = os.path.basename(audio_file)
                print(f"[WORKER] å¼€å§‹å¤„ç†: {filename}")
                
                def timeout_handler(signum, frame):
                    raise TimeoutError(f"å¤„ç† {filename} è¶…æ—¶")
                
                try:
                    # è®¾ç½®60ç§’è¶…æ—¶
                    signal.signal(signal.SIGALRM, timeout_handler)
                    signal.alarm(60)
                    
                    start_time = time.time()
                    features = self.feature_extractor.extract_all_features(audio_file)
                    
                    feature_vector = []
                    for name in self.get_feature_names():
                        feature_vector.append(features.get(name, 0.0))
                    
                    signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
                    elapsed = time.time() - start_time
                    print(f"[WORKER] {filename} å¤„ç†å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f}s")
                    return feature_vector, label
                    
                except TimeoutError as e:
                    signal.alarm(0)
                    print(f"[TIMEOUT] {filename}: {e}")
                    return None, None
                except Exception as e:
                    signal.alarm(0)
                    print(f"[ERROR] ç‰¹å¾æå–å¤±è´¥ {filename}: {e}")
                    return None, None
            
            # é™ä½å¹¶è¡Œåº¦é¿å… audioread å¡ä½
            results = Parallel(n_jobs=1, verbose=5)(
                delayed(extract_single_feature)(af, lbl) 
                for af, lbl in zip(audio_files, labels)
            )
            
            # è¿‡æ»¤æœ‰æ•ˆç»“æœ
            features_list = []
            valid_labels = []
            for feat, lbl in results:
                if feat is not None:
                    features_list.append(feat)
                    valid_labels.append(lbl)
                    
        except ImportError:
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            print("å¹¶è¡Œå¤„ç†ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†...")
            try:
                from tqdm import tqdm
                progress_bar = tqdm(zip(audio_files, labels), total=len(audio_files), desc="ç‰¹å¾æå–è¿›åº¦")
            except ImportError:
                progress_bar = zip(audio_files, labels)
                
            features_list = []
            valid_labels = []
            
            for i, (audio_file, label) in enumerate(progress_bar):
                if 'tqdm' not in str(type(progress_bar)):
                    print(f"å¤„ç† {i+1}/{len(audio_files)}: {os.path.basename(audio_file)}")
                try:
                    features = self.feature_extractor.extract_all_features(audio_file)
                    feature_vector = []
                    for name in self.get_feature_names():
                        feature_vector.append(features.get(name, 0.0))
                    
                    features_list.append(feature_vector)
                    valid_labels.append(label)
                    
                except Exception as e:
                    print(f"ç‰¹å¾æå–å¤±è´¥ {audio_file}: {e}")
                    continue
        
        if len(features_list) == 0:
            raise RuntimeError("é”™è¯¯: æ— æ³•æå–ä»»ä½•æœ‰æ•ˆç‰¹å¾ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ ¼å¼")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        X = np.array(features_list)
        y = np.array(valid_labels)
        
        print(f"æœ‰æ•ˆç‰¹å¾çŸ©é˜µ: {X.shape}")
        
        # æ•°æ®åˆ’åˆ†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # è®­ç»ƒæ¨¡å‹
        self.model = self._create_interpretable_ensemble()
        self.model.fit(X_train_scaled, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        train_score = self.model.score(X_train_scaled, y_train)
        test_score = self.model.score(X_test_scaled, y_test)
        
        print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_score:.3f}")
        print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.3f}")
        
        # è¿‡æ‹Ÿåˆæ£€æµ‹å’Œè­¦å‘Š
        overfitting_gap = train_score - test_score
        if overfitting_gap > 0.15:
            print(f"âš ï¸  æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼è®­ç»ƒ-æµ‹è¯•å‡†ç¡®ç‡å·®è·: {overfitting_gap:.3f}")
            print("   å»ºè®®ï¼šå¢åŠ æ­£åˆ™åŒ–å¼ºåº¦æˆ–å‡å°‘æ¨¡å‹å¤æ‚åº¦")
        elif overfitting_gap > 0.10:
            print(f"âš¡ è½»å¾®è¿‡æ‹Ÿåˆï¼Œè®­ç»ƒ-æµ‹è¯•å‡†ç¡®ç‡å·®è·: {overfitting_gap:.3f}")
        else:
            print(f"âœ… æ¨¡å‹æ³›åŒ–è‰¯å¥½ï¼Œè®­ç»ƒ-æµ‹è¯•å‡†ç¡®ç‡å·®è·: {overfitting_gap:.3f}")
        
        # è‡ªé€‚åº”é˜ˆå€¼ä¼˜åŒ–
        self.optimal_threshold = self._find_optimal_threshold(X_test_scaled, y_test)
        print(f"æœ€ä¼˜é˜ˆå€¼: {self.optimal_threshold:.3f}")
        
        # å¢å¼ºçš„äº¤å‰éªŒè¯
        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5, scoring='f1')
        cv_mean = np.mean(cv_scores)
        cv_std = np.std(cv_scores)
        print(f"äº¤å‰éªŒè¯F1-score: {cv_mean:.3f} (+/- {cv_std * 2:.3f})")
        
        # æ¨¡å‹ç¨³å®šæ€§è¯„ä¼°
        if cv_std > 0.1:
            print("âš ï¸  æ¨¡å‹ç¨³å®šæ€§è¾ƒå·®ï¼Œå»ºè®®å¢åŠ è®­ç»ƒæ•°æ®æˆ–è°ƒæ•´å‚æ•°")
        else:
            print("âœ… æ¨¡å‹ç¨³å®šæ€§è‰¯å¥½")
            
        # æ˜¾ç¤ºéšæœºæ£®æ—çš„è¢‹å¤–å¾—åˆ†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self.model.named_estimators_['rf'], 'oob_score_'):
            oob_score = self.model.named_estimators_['rf'].oob_score_
            print(f"éšæœºæ£®æ—è¢‹å¤–å¾—åˆ†: {oob_score:.3f}")
            
            # è¢‹å¤–å¾—åˆ†ä¸æµ‹è¯•å¾—åˆ†çš„ä¸€è‡´æ€§æ£€æŸ¥
            oob_test_diff = abs(oob_score - test_score)
            if oob_test_diff < 0.05:
                print("âœ… è¢‹å¤–å¾—åˆ†ä¸æµ‹è¯•å¾—åˆ†ä¸€è‡´ï¼Œæ¨¡å‹å¯é ")
            else:
                print(f"âš ï¸  è¢‹å¤–å¾—åˆ†ä¸æµ‹è¯•å¾—åˆ†å·®å¼‚è¾ƒå¤§: {oob_test_diff:.3f}")
        
        # è®­ç»ƒå®Œæˆåè‡ªåŠ¨ä¿å­˜æ¨¡å‹ç¼“å­˜
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹ç¼“å­˜...")
        self.save_model_cache()
        
        return self
    
    def _find_optimal_threshold(self, X_test, y_test):
        """åœ¨éªŒè¯é›†ä¸Šå¯»æ‰¾æœ€ä¼˜é˜ˆå€¼ï¼ˆæœ€å¤§åŒ–F1-scoreï¼‰"""
        from sklearn.metrics import f1_score
        
        # è·å–é¢„æµ‹æ¦‚ç‡
        probabilities = self.model.predict_proba(X_test)[:, 1]
        
        best_threshold = 0.5
        best_f1 = 0.0
        
        # æ‰«æé˜ˆå€¼èŒƒå›´ 0.3-0.7
        for threshold in np.arange(0.3, 0.71, 0.02):
            predictions = (probabilities >= threshold).astype(int)
            f1 = f1_score(y_test, predictions, average='weighted')
            
            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold
        
        print(f"æœ€ä½³F1-score: {best_f1:.3f} (é˜ˆå€¼={best_threshold:.3f})")
        return best_threshold
    
    def get_feature_names(self):
        """è·å–å¢å¼ºæ•°å­¦ç‰¹å¾åç§°åˆ—è¡¨ï¼ˆ42ç»´ï¼‰- åŸºäºé‡è¦æ€§åˆ†æä¼˜åŒ–"""
        return [
            # é¢‘åŸŸæ•°å­¦ç‰¹å¾ (13ç»´) - åŸºäºå‚…é‡Œå¶åˆ†æå’Œç»Ÿè®¡å­¦ï¼Œå¢å¼ºå…³é”®ç‰¹å¾
            'spectral_centroid_mean', 'spectral_centroid_std', 'centroid_stability', 'centroid_trajectory_smoothness',
            'spectral_bandwidth_mean', 'spectral_bandwidth_std',
            'spectral_entropy_mean', 'spectral_entropy_std',
            'spectral_flatness_mean', 'spectral_flatness_std',
            'harmonic_noise_ratio', 'harmonic_complexity', 'hnr_stability',
            
            # æ—¶åŸŸæ•°å­¦ç‰¹å¾ (17ç»´) - åŸºäºç»Ÿè®¡å­¦å’Œä¿¡å·å¤„ç†ï¼Œå¢å¼ºZCRç‰¹å¾
            'amplitude_mean', 'amplitude_std', 'amplitude_skewness', 'amplitude_kurtosis',
            'zcr_mean', 'zcr_std', 'zcr_entropy', 'zcr_stability', 'zcr_outlier_ratio',
            'rms_mean', 'rms_std', 'dynamic_range', 'compression_ratio',
            'energy_variation', 'energy_regularity',
            'periodicity_strength', 'fundamental_period',
            
            # éŸ³ä¹ç†è®ºæ•°å­¦ç‰¹å¾ (13ç»´) - åŸºäºéŸ³ä¹å£°å­¦ç†è®º
            'mfcc_mean_1', 'mfcc_mean_2', 'mfcc_std_1', 'mfcc_std_2', 'mfcc_correlation',
            'chroma_std', 'pitch_stability', 'pitch_entropy',
            'rhythm_intensity_mean', 'rhythm_intensity_std', 'rhythm_regularity',
            'timbre_brightness', 'timbre_brightness_var', 'timbre_rolloff'
        ]
    
    def train(self, training_data_path="é™„ä»¶å…­ï¼šè®­ç»ƒæ•°æ®"):
        """è®­ç»ƒæ¨¡å‹çš„ä¸»è¦æ¥å£"""
        return self.train_with_real_data(training_data_path)
    
    def predict_single(self, audio_file):
        """é¢„æµ‹å•ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼‰"""
        features = self.feature_extractor.extract_all_features(audio_file)
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
        feature_vector = []
        for name in self.get_feature_names():
            feature_vector.append(features.get(name, 0.0))
        
        X = np.array(feature_vector).reshape(1, -1)
        X_scaled = self.scaler.transform(X)
        
        probability = self.model.predict_proba(X_scaled)[0]
        
        # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼è¿›è¡Œé¢„æµ‹
        threshold = getattr(self, 'optimal_threshold', 0.5)
        prediction = int(probability[1] >= threshold)
        
        return {
            'prediction': prediction,
            'probability_ai': probability[1],
            'probability_human': probability[0],
            'confidence': probability[1],  # æ·»åŠ confidenceå­—æ®µå…¼å®¹æ”»å‡»æµ‹è¯•
            'threshold_used': threshold,
            'features': features
        }
    
    def predict_single_from_array(self, audio_array, sr=22050):
        """ä»éŸ³é¢‘æ•°ç»„é¢„æµ‹ï¼ˆç”¨äºæ”»å‡»æµ‹è¯•ï¼‰"""
        try:
            # ä¸´æ—¶ä¿å­˜éŸ³é¢‘æ•°ç»„åˆ°æ–‡ä»¶
            import soundfile as sf
            temp_file = "temp_audio_for_prediction.wav"
            sf.write(temp_file, audio_array, sr)
            
            # ä½¿ç”¨ç°æœ‰çš„é¢„æµ‹æ–¹æ³•
            result = self.predict_single(temp_file)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            import os
            if os.path.exists(temp_file):
                os.remove(temp_file)
            
            return result
            
        except Exception as e:
            print(f"æ•°ç»„é¢„æµ‹é”™è¯¯: {e}")
            return {
                'prediction': 0,
                'confidence': 0.5,
                'probability_ai': 0.5,
                'probability_human': 0.5,
                'features': {}
            }
    
    def get_feature_importance_explanation(self):
        """è·å–æ•°å­¦ç‰¹å¾é‡è¦æ€§çš„å¯è§£é‡Šæ€§åˆ†æ"""
        if hasattr(self.model.named_estimators_['rf'], 'feature_importances_'):
            importance = self.model.named_estimators_['rf'].feature_importances_
            feature_names = self.get_feature_names()
            feature_importance = list(zip(feature_names, importance))
            feature_importance.sort(key=lambda x: x[1], reverse=True)
            
            print("\n=== æ•°å­¦ç‰¹å¾é‡è¦æ€§ä¸å¯è§£é‡Šæ€§åˆ†æ ===")
            
            # å¢å¼ºç‰¹å¾è§£é‡Šå­—å…¸ - åŸºäºæ•°å­¦ç†è®ºçš„å¯è§£é‡Šæ€§
            feature_explanations = {
                # é¢‘åŸŸç‰¹å¾è§£é‡Š
                'spectral_centroid_mean': 'é¢‘è°±è´¨å¿ƒå‡å€¼ - åæ˜ éŸ³è‰²äº®åº¦ï¼ŒAIéŸ³ä¹é€šå¸¸æ›´ç¨³å®š',
                'spectral_centroid_std': 'é¢‘è°±è´¨å¿ƒæ ‡å‡†å·® - åæ˜ éŸ³è‰²å˜åŒ–ç¨‹åº¦',
                'centroid_trajectory_smoothness': 'è´¨å¿ƒè½¨è¿¹å¹³æ»‘åº¦ - AIéŸ³ä¹è´¨å¿ƒå˜åŒ–è¿‡äºå¹³æ»‘',
                'spectral_entropy_mean': 'é¢‘è°±ç†µå‡å€¼ - åæ˜ é¢‘è°±å¤æ‚åº¦ï¼ŒAIéŸ³ä¹é€šå¸¸æ›´è§„å¾‹',
                'harmonic_noise_ratio': 'è°æ³¢å™ªå£°æ¯” - åæ˜ éŸ³ä¹çº¯å‡€åº¦ï¼ŒAIéŸ³ä¹è°æ³¢æˆåˆ†æ›´å¼º',
                'harmonic_complexity': 'è°æ³¢å¤æ‚åº¦ - AIéŸ³ä¹è°æ³¢ç»“æ„è¿‡äºç®€å•è§„æ•´',
                'hnr_stability': 'è°æ³¢-å™ªå£°å¹³è¡¡ç¨³å®šæ€§ - AIéŸ³ä¹å¹³è¡¡è¿‡äºç¨³å®š',
                'spectral_flatness_mean': 'é¢‘è°±å¹³å¦åº¦ - åæ˜ å™ªå£°ç‰¹æ€§ï¼ŒAIéŸ³ä¹æ›´æ¥è¿‘ç™½å™ªå£°',
                
                # æ—¶åŸŸç‰¹å¾è§£é‡Š
                'amplitude_skewness': 'å¹…åº¦ååº¦ - åæ˜ éŸ³é¢‘åŠ¨æ€åˆ†å¸ƒçš„ä¸å¯¹ç§°æ€§',
                'amplitude_kurtosis': 'å¹…åº¦å³°åº¦ - åæ˜ éŸ³é¢‘åŠ¨æ€åˆ†å¸ƒçš„å°–é”ç¨‹åº¦',
                'zcr_mean': 'é›¶äº¤å‰ç‡å‡å€¼ - åæ˜ é«˜é¢‘å†…å®¹ï¼ŒAIäººå£°å¸¸æœ‰ä¼ªé«˜é¢‘',
                'zcr_stability': 'ZCRç¨³å®šæ€§ - AIéŸ³ä¹é›¶äº¤å‰ç‡å˜åŒ–è¿‡äºè§„å¾‹',
                'zcr_outlier_ratio': 'ZCRå¼‚å¸¸æ¯”ä¾‹ - AIéŸ³ä¹å¼‚å¸¸é›¶äº¤å‰ç‡æ›´é¢‘ç¹',
                'dynamic_range': 'åŠ¨æ€èŒƒå›´ - AIéŸ³ä¹é€šå¸¸å‹ç¼©æ›´å¼ºï¼ŒåŠ¨æ€èŒƒå›´è¾ƒå°',
                'compression_ratio': 'å‹ç¼©æ¯” - åæ˜ åŠ¨æ€å‹ç¼©ç¨‹åº¦',
                'periodicity_strength': 'å‘¨æœŸæ€§å¼ºåº¦ - åæ˜ éŸ³ä¹è§„å¾‹æ€§ï¼ŒAIéŸ³ä¹æ›´è§„å¾‹',
                
                # éŸ³ä¹ç†è®ºç‰¹å¾è§£é‡Š
                'mfcc_correlation': 'MFCCç›¸å…³æ€§ - åæ˜ éŸ³è‰²ä¸€è‡´æ€§',
                'pitch_stability': 'éŸ³é«˜ç¨³å®šæ€§ - åæ˜ è°ƒæ€§ç¨³å®šç¨‹åº¦',
                'rhythm_regularity': 'èŠ‚å¥è§„å¾‹æ€§ - AIéŸ³ä¹èŠ‚æ‹é€šå¸¸æ›´è§„å¾‹',
                'timbre_brightness': 'éŸ³è‰²äº®åº¦ - åæ˜ é«˜é¢‘èƒ½é‡åˆ†å¸ƒ'
            }
            
            print("å‰10ä¸ªæœ€é‡è¦çš„æ•°å­¦ç‰¹å¾:")
            for i, (name, imp) in enumerate(feature_importance[:10], 1):
                explanation = feature_explanations.get(name, 'è¯¥ç‰¹å¾åæ˜ éŸ³é¢‘çš„æ•°å­¦ç»Ÿè®¡æ€§è´¨')
                print(f"{i:2d}. {name:<25} {imp:.4f} - {explanation}")
            
            # æŒ‰ç±»åˆ«ç»Ÿè®¡é‡è¦æ€§
            freq_importance = sum(imp for name, imp in feature_importance if 'spectral' in name or 'harmonic' in name)
            temp_importance = sum(imp for name, imp in feature_importance if any(x in name for x in ['amplitude', 'zcr', 'rms', 'dynamic', 'energy', 'period']))
            music_importance = sum(imp for name, imp in feature_importance if any(x in name for x in ['mfcc', 'chroma', 'pitch', 'rhythm', 'timbre']))
            
            print(f"\n=== ç‰¹å¾ç±»åˆ«é‡è¦æ€§åˆ†å¸ƒ ===")
            print(f"é¢‘åŸŸæ•°å­¦ç‰¹å¾æ€»é‡è¦æ€§: {freq_importance:.3f}")
            print(f"æ—¶åŸŸæ•°å­¦ç‰¹å¾æ€»é‡è¦æ€§: {temp_importance:.3f}")
            print(f"éŸ³ä¹ç†è®ºç‰¹å¾æ€»é‡è¦æ€§: {music_importance:.3f}")
            
            return feature_importance
        return []


def test_single_file():
    """æµ‹è¯•å•ä¸ªæ–‡ä»¶çš„æ£€æµ‹"""
    detector = MathematicalAIMusicDetector()
    
    try:
        print("è®­ç»ƒæ¨¡å‹...")
        detector.train()
        
        # æµ‹è¯•é™„ä»¶å››
        test_file = "é™„ä»¶å››ï¼šæµ‹è¯•éŸ³ä¹.mp3"
        if os.path.exists(test_file):
            print(f"\næµ‹è¯•æ–‡ä»¶: {test_file}")
            result = detector.predict_single(test_file)
            print(f"é¢„æµ‹ç»“æœ: {'AIç”Ÿæˆ' if result['prediction'] == 1 else 'äººç±»åˆ›ä½œ'}")
            print(f"AIæ¦‚ç‡: {result['probability_ai']:.3f}")
            print(f"ä½¿ç”¨é˜ˆå€¼: {result['threshold_used']:.3f}")
        else:
            print("æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        test_single_file()
    else:
        # å®Œæ•´è®­ç»ƒå’Œæµ‹è¯•
        print("=== åŸºäºæ•°å­¦ç†è®ºçš„AIéŸ³ä¹æ£€æµ‹å™¨ ===")
        print("è®¾è®¡ç†å¿µï¼š")
        print("1. æ•°å­¦ç†è®ºåŸºç¡€ï¼šå‚…é‡Œå¶åˆ†æã€ç»Ÿè®¡å­¦ã€ä¿¡æ¯è®º")
        print("2. ç‰¹å¾å¯è§£é‡Šæ€§ï¼šæ¯ä¸ªç‰¹å¾éƒ½æœ‰æ˜ç¡®çš„æ•°å­¦å’Œç‰©ç†å«ä¹‰")
        print("3. å¤šå±‚æ¬¡åˆ†æï¼šé¢‘åŸŸã€æ—¶åŸŸã€éŸ³ä¹ç†è®ºä¸‰ä¸ªç»´åº¦")
        print("4. ç»Ÿè®¡å­¦æ–¹æ³•ï¼šæ¦‚ç‡åˆ†å¸ƒã€ç†µç†è®ºã€é«˜é˜¶çŸ©åˆ†æ")
        print()
        
        detector = MathematicalAIMusicDetector()
        
        try:
            print("ä½¿ç”¨é™„ä»¶å…­è®­ç»ƒæ•°æ®è®­ç»ƒæ•°å­¦ç‰¹å¾æ¨¡å‹...")
            detector.train()
            
            print("\nâœ… åŸºäºæ•°å­¦ç†è®ºçš„AIéŸ³ä¹æ£€æµ‹å™¨è®­ç»ƒå®Œæˆ!")
            print("ğŸ“Š ç‰¹å¾ç»´åº¦ï¼š33ç»´æ•°å­¦ç‰¹å¾")
            print("ğŸ”¬ ç†è®ºåŸºç¡€ï¼šä¿¡å·å¤„ç†ã€ç»Ÿè®¡å­¦ã€éŸ³ä¹å£°å­¦")
            print("ğŸ¯ å¯è§£é‡Šæ€§ï¼šæ¯ä¸ªç‰¹å¾éƒ½æœ‰æ˜ç¡®çš„æ•°å­¦å«ä¹‰")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„ç‰¹å¾é‡è¦æ€§åˆ†æ
            detector.get_feature_importance_explanation()
            
            print("\n=== æ•°å­¦ç‰¹å¾ä½“ç³»è¯´æ˜ ===")
            print("é¢‘åŸŸç‰¹å¾(10ç»´)ï¼šåŸºäºçŸ­æ—¶å‚…é‡Œå¶å˜æ¢å’Œé¢‘è°±åˆ†æ")
            print("- é¢‘è°±è´¨å¿ƒã€å¸¦å®½ï¼šåæ˜ éŸ³è‰²ç‰¹å¾")
            print("- é¢‘è°±ç†µã€å¹³å¦åº¦ï¼šåæ˜ é¢‘è°±å¤æ‚åº¦å’Œå™ªå£°ç‰¹æ€§")
            print("- è°æ³¢-å™ªå£°æ¯”ï¼šåæ˜ éŸ³ä¹çº¯å‡€åº¦")
            print()
            print("æ—¶åŸŸç‰¹å¾(15ç»´)ï¼šåŸºäºç»Ÿè®¡å­¦å’Œä¿¡å·å¤„ç†ç†è®º")
            print("- å¹…åº¦ç»Ÿè®¡ï¼šå‡å€¼ã€æ–¹å·®ã€ååº¦ã€å³°åº¦")
            print("- é›¶äº¤å‰ç‡ï¼šåæ˜ é¢‘ç‡å†…å®¹")
            print("- RMSèƒ½é‡ï¼šåŠ¨æ€èŒƒå›´å’Œå‹ç¼©ç‰¹æ€§")
            print("- è‡ªç›¸å…³ï¼šå‘¨æœŸæ€§å’Œè§„å¾‹æ€§åˆ†æ")
            print()
            print("éŸ³ä¹ç†è®ºç‰¹å¾(13ç»´)ï¼šåŸºäºéŸ³ä¹å£°å­¦å’Œæ„ŸçŸ¥ç†è®º")
            print("- MFCCï¼šåŸºäºäººè€³æ„ŸçŸ¥çš„å€’è°±åˆ†æ")
            print("- è‰²åº¦ï¼šåŸºäºåäºŒå¹³å‡å¾‹çš„éŸ³é«˜åˆ†æ")
            print("- èŠ‚å¥ï¼šåŸºäºé¢‘è°±æµé‡çš„èŠ‚æ‹æ£€æµ‹")
            print("- éŸ³è‰²ï¼šé¢‘è°±é‡å¿ƒå’Œæ»šé™ç‚¹åˆ†æ")
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            print("è¯·ç¡®ä¿é™„ä»¶å…­ï¼šè®­ç»ƒæ•°æ®ç›®å½•å­˜åœ¨ä¸”åŒ…å«éŸ³é¢‘æ–‡ä»¶")