#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®æ­£ç‰ˆAIéŸ³ä¹æ£€æµ‹å™¨
è§£å†³è®­ç»ƒæ•°æ®æ ‡ç­¾é”™è¯¯é—®é¢˜ï¼Œé‡æ–°è®­ç»ƒæ¨¡å‹
"""

from ai_music_detector import MathematicalAIMusicDetector
import os
import glob
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib

class CorrectedAIMusicDetector(MathematicalAIMusicDetector):
    """ä¿®æ­£ç‰ˆAIéŸ³ä¹æ£€æµ‹å™¨ - è§£å†³æ ‡ç­¾é”™è¯¯é—®é¢˜"""
    
    def __init__(self):
        super().__init__()
        # ä½¿ç”¨ä¿®æ­£åçš„æ¨¡å‹ç¼“å­˜è·¯å¾„
        self.model_cache_path = "ai_music_detector_corrected_model.pkl"
        self.scaler_cache_path = "ai_music_detector_corrected_scaler.pkl"
        self.threshold_cache_path = "ai_music_detector_corrected_threshold.pkl"
    
    def get_corrected_labels(self):
        """è·å–ä¿®æ­£åçš„æ ‡ç­¾æ˜ å°„"""
        return {
            # AIç”ŸæˆéŸ³ä¹ï¼ˆæ ‡ç­¾=1ï¼‰- ä¿®æ­£ååŒ…å«tianyi_daddy
            'ai_folders': [
                'alice',           # AIè™šæ‹Ÿæ­Œæ‰‹
                'china_vocaloid',  # ä¸­æ–‡è™šæ‹Ÿæ­Œæ‰‹
                'game',           # æ¸¸æˆAIéŸ³ä¹
                'gugugaga',       # AIç”Ÿæˆ
                'ikun',           # AIç”Ÿæˆ
                'manbo',          # AIç”Ÿæˆ
                'yiwu',           # AIç”Ÿæˆ
                'tianyi_daddy'    # ğŸ”„ ä¿®æ­£ï¼šæ´›å¤©ä¾ç›¸å…³ï¼Œåº”ä¸ºAIç±»
            ],
            # äººç±»åˆ›ä½œéŸ³ä¹ï¼ˆæ ‡ç­¾=0ï¼‰
            'human_folders': [
                'hanser',         # äººç±»æ­Œæ‰‹
                'xiangsi',        # äººç±»åˆ›ä½œï¼ˆå¾…éªŒè¯ï¼‰
                'xiexiemiao~'     # äººç±»åˆ›ä½œ
            ]
        }
    
    def train_with_corrected_data(self, training_data_path="é™„ä»¶å…­ï¼šè®­ç»ƒæ•°æ®"):
        """ä½¿ç”¨ä¿®æ­£åçš„æ ‡ç­¾é‡æ–°è®­ç»ƒæ¨¡å‹"""
        print("ğŸ”„ ä½¿ç”¨ä¿®æ­£åçš„æ ‡ç­¾é‡æ–°è®­ç»ƒæ¨¡å‹...")
        print("ä¸»è¦ä¿®æ­£ï¼štianyi_daddy ä»äººç±»ç±»åˆ«ç§»è‡³AIç±»åˆ«")
        
        # é¦–å…ˆå°è¯•ä»ç¼“å­˜åŠ è½½
        if self.load_model_cache():
            print("âœ… ä»ç¼“å­˜åŠ è½½ä¿®æ­£ç‰ˆæ¨¡å‹æˆåŠŸ")
            return self
        
        print("ğŸ“š å¼€å§‹é‡æ–°è®­ç»ƒä¿®æ­£ç‰ˆæ¨¡å‹...")
        from sklearn.model_selection import train_test_split
        
        if not os.path.exists(training_data_path):
            print(f"é”™è¯¯ï¼šè®­ç»ƒæ•°æ®è·¯å¾„ä¸å­˜åœ¨: {training_data_path}")
            return self
        
        # è·å–ä¿®æ­£åçš„æ ‡ç­¾
        labels_config = self.get_corrected_labels()
        ai_folders = labels_config['ai_folders']
        human_folders = labels_config['human_folders']
        
        print(f"\n=== ä¿®æ­£åçš„æ•°æ®æ ‡ç­¾ ===")
        print(f"AIç±»åˆ«({len(ai_folders)}ä¸ªæ–‡ä»¶å¤¹): {ai_folders}")
        print(f"äººç±»ç±»åˆ«({len(human_folders)}ä¸ªæ–‡ä»¶å¤¹): {human_folders}")
        
        # æ”¶é›†è®­ç»ƒæ•°æ®
        X_features = []
        y_labels = []
        file_info = []
        
        # å¤„ç†AIç±»åˆ«
        for folder in ai_folders:
            folder_path = os.path.join(training_data_path, folder)
            if not os.path.exists(folder_path):
                print(f"âš ï¸ æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè·³è¿‡: {folder}")
                continue
                
            audio_files = glob.glob(os.path.join(folder_path, "*.mp3")) + \
                         glob.glob(os.path.join(folder_path, "*.aac"))
            
            print(f"å¤„ç†AIç±»åˆ« {folder}: {len(audio_files)}ä¸ªæ–‡ä»¶")
            
            # é™åˆ¶æ¯ä¸ªæ–‡ä»¶å¤¹æœ€å¤š50ä¸ªæ ·æœ¬
            if len(audio_files) > 50:
                audio_files = np.random.choice(audio_files, 50, replace=False)
            
            for audio_file in audio_files:
                try:
                    features = self.feature_extractor.extract_all_features(audio_file)
                    if features is not None and len(features) > 0:
                        X_features.append(features)
                        y_labels.append(1)  # AIæ ‡ç­¾
                        file_info.append(f"{folder}/{os.path.basename(audio_file)}")
                except Exception as e:
                    print(f"ç‰¹å¾æå–å¤±è´¥ {audio_file}: {e}")
        
        # å¤„ç†äººç±»ç±»åˆ«
        for folder in human_folders:
            folder_path = os.path.join(training_data_path, folder)
            if not os.path.exists(folder_path):
                print(f"âš ï¸ æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè·³è¿‡: {folder}")
                continue
                
            audio_files = glob.glob(os.path.join(folder_path, "*.mp3")) + \
                         glob.glob(os.path.join(folder_path, "*.aac"))
            
            print(f"å¤„ç†äººç±»ç±»åˆ« {folder}: {len(audio_files)}ä¸ªæ–‡ä»¶")
            
            # é™åˆ¶æ¯ä¸ªæ–‡ä»¶å¤¹æœ€å¤š50ä¸ªæ ·æœ¬
            if len(audio_files) > 50:
                audio_files = np.random.choice(audio_files, 50, replace=False)
            
            for audio_file in audio_files:
                try:
                    features = self.feature_extractor.extract_all_features(audio_file)
                    if features is not None and len(features) > 0:
                        X_features.append(features)
                        y_labels.append(0)  # äººç±»æ ‡ç­¾
                        file_info.append(f"{folder}/{os.path.basename(audio_file)}")
                except Exception as e:
                    print(f"ç‰¹å¾æå–å¤±è´¥ {audio_file}: {e}")
        
        if len(X_features) == 0:
            print("é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸæå–åˆ°ç‰¹å¾")
            return self
        
        # æ£€æŸ¥ç‰¹å¾ç»´åº¦ä¸€è‡´æ€§
        feature_lengths = [len(f) for f in X_features]
        if len(set(feature_lengths)) > 1:
            print(f"è­¦å‘Šï¼šç‰¹å¾ç»´åº¦ä¸ä¸€è‡´: {set(feature_lengths)}")
            # ä½¿ç”¨æœ€å¸¸è§çš„ç»´åº¦
            most_common_length = max(set(feature_lengths), key=feature_lengths.count)
            print(f"ä½¿ç”¨æœ€å¸¸è§çš„ç‰¹å¾ç»´åº¦: {most_common_length}")
            
            # é‡æ–°æ„å»ºç‰¹å¾å’Œæ ‡ç­¾åˆ—è¡¨
            filtered_X = []
            filtered_y = []
            for i, f in enumerate(X_features):
                if len(f) == most_common_length:
                    filtered_X.append(f)
                    filtered_y.append(y_labels[i])
            
            X_features = filtered_X
            y_labels = filtered_y
        
        X = np.array(X_features)
        y = np.array(y_labels)
        
        print(f"\n=== ä¿®æ­£åçš„æ•°æ®ç»Ÿè®¡ ===")
        print(f"æ€»æ ·æœ¬æ•°: {len(X)}")
        print(f"AIæ ·æœ¬æ•°: {np.sum(y == 1)}")
        print(f"äººç±»æ ·æœ¬æ•°: {np.sum(y == 0)}")
        print(f"ç‰¹å¾ç»´åº¦: {X.shape[1] if X.ndim > 1 else 'N/A'}")
        
        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        
        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"\nè®­ç»ƒé›†: {len(X_train)}, æµ‹è¯•é›†: {len(X_test)}")
        
        # åˆ›å»ºå¹¶è®­ç»ƒé›†æˆæ¨¡å‹
        self.model = self._create_interpretable_ensemble()
        
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        self.model.fit(X_train, y_train)
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)[:, 1]
        
        train_score = self.model.score(X_train, y_train)
        test_score = self.model.score(X_test, y_test)
        
        print(f"\n=== ä¿®æ­£ç‰ˆæ¨¡å‹æ€§èƒ½ ===")
        print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_score:.3f}")
        print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.3f}")
        
        # å¯»æ‰¾æœ€ä¼˜é˜ˆå€¼
        self.optimal_threshold = self._find_optimal_threshold(X_test, y_test)
        
        # ä½¿ç”¨æœ€ä¼˜é˜ˆå€¼é‡æ–°é¢„æµ‹
        y_pred_optimal = (y_pred_proba >= self.optimal_threshold).astype(int)
        
        print(f"\n=== ä½¿ç”¨æœ€ä¼˜é˜ˆå€¼ {self.optimal_threshold:.3f} çš„ç»“æœ ===")
        print(classification_report(y_test, y_pred_optimal, target_names=['äººç±»åˆ›ä½œ', 'AIç”Ÿæˆ']))
        
        # ä¿å­˜æ¨¡å‹ç¼“å­˜
        print("\nğŸ’¾ ä¿å­˜ä¿®æ­£ç‰ˆæ¨¡å‹ç¼“å­˜...")
        self.save_model_cache()
        
        return self
    
    def analyze_correction_effect(self, target_audio="é™„ä»¶å››ï¼šæµ‹è¯•éŸ³ä¹.mp3"):
        """åˆ†æä¿®æ­£åæ¨¡å‹å¯¹é™„ä»¶å››çš„é¢„æµ‹æ•ˆæœ"""
        if not os.path.exists(target_audio):
            print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {target_audio}")
            return
        
        print(f"\n=== ä¿®æ­£ç‰ˆæ¨¡å‹å¯¹{target_audio}çš„åˆ†æ ===")
        
        # ä½¿ç”¨ä¿®æ­£ç‰ˆæ¨¡å‹é¢„æµ‹
        result = self.predict_single(target_audio)
        
        print(f"ä¿®æ­£ç‰ˆé¢„æµ‹ç»“æœ:")
        print(f"  é¢„æµ‹: {'AIç”Ÿæˆ' if result['prediction'] else 'äººç±»åˆ›ä½œ'}")
        print(f"  AIæ¦‚ç‡: {result['probability_ai']:.3f}")
        print(f"  é˜ˆå€¼: {self.optimal_threshold:.3f}")
        print(f"  å®é™…æ ‡ç­¾: AIç”Ÿæˆï¼ˆæ ¹æ®é¢˜ç›®è¯´æ˜ï¼‰")
        print(f"  åˆ¤æ–­æ­£ç¡®æ€§: {'âœ… æ­£ç¡®' if result['prediction'] else 'âŒ é”™è¯¯'}")
        
        return result

def main():
    """ä¸»å‡½æ•° - è®­ç»ƒä¿®æ­£ç‰ˆæ¨¡å‹å¹¶æµ‹è¯•"""
    print("="*60)
    print("ä¿®æ­£ç‰ˆAIéŸ³ä¹æ£€æµ‹å™¨")
    print("è§£å†³è®­ç»ƒæ•°æ®æ ‡ç­¾é”™è¯¯é—®é¢˜")
    print("="*60)
    
    # åˆ›å»ºä¿®æ­£ç‰ˆæ£€æµ‹å™¨
    corrected_detector = CorrectedAIMusicDetector()
    
    # é‡æ–°è®­ç»ƒ
    corrected_detector.train_with_corrected_data()
    
    # åˆ†æä¿®æ­£æ•ˆæœ
    corrected_detector.analyze_correction_effect()
    
    print("\n" + "="*60)
    print("ä¿®æ­£ç‰ˆæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("å¦‚æœä¿®æ­£æˆåŠŸï¼Œé™„ä»¶å››åº”è¯¥è¢«æ­£ç¡®è¯†åˆ«ä¸ºAIç”Ÿæˆ")
    print("="*60)

if __name__ == "__main__":
    main()
